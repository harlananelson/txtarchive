
# Cell 1
#|include: false
#|echo: false
import os
import sys
from pathlib import Path
import getpass
from IPython.display import display, Javascript, HTML

# Setup Environment
display(Javascript('IPython.notebook.kernel.execute("notebook_url = " + "\'" + window.location + "\'");'))

# Cell 2
#|include: false
#|echo: false
# Import lhn and setup paths
from lhn.header import *
import lhn as h
from pyspark.sql import functions as F

# Standard LHN Setup
current_directory, notebook_path, python_path, basePath, project = h.setup_environment(notebook_url)

# Load Configuration
funCall = {
    'config_file': '000-config.yaml',
    'process_all': True,
    'debug': True
}
resource = h.Resources(**h.setFunctionParameters(h.Resources, funCall, config_dict=locals()))
locals().update(resource.load_into_local(everything=False))

# Cell 3
# Markdown
"""
# 015 - Prepare Phenotyping Data

**Purpose:** Efficiently extract and standardize EHR inputs for the `scd_phenotyping` Python package.
This notebook acts as a "Factory" that reads raw LHN tables and outputs clean Parquet files.

**Outputs:**
1. `enc_input.parquet`: Standardized encounters (IP/OP/ER).
2. `icd_input.parquet`: Diagnosis history (filtered to relevant Sickle/Thal codes).
3. `lab_input.parquet`: Hemoglobin fractionation labs.
"""

# Cell 4
# Configuration and Constants

# Define Output Paths
OUTPUT_BASE = "/home/hnelson3/work/Users/hnelson3/inst/extdata/SickleCell/phenotyping_inputs"
PATH_ENC  = f"{OUTPUT_BASE}/enc_input.parquet"
PATH_ICD  = f"{OUTPUT_BASE}/icd_input.parquet"
PATH_LAB  = f"{OUTPUT_BASE}/lab_input.parquet"

# Define Regex for Diagnosis Filter (Matches scd_phenotyping package config)
# We apply this in Spark to reduce file size before the Python package sees it.
ICD_REGEX_SUPERSET = (
    # SCD (e.g., D57.0, 282.6)
    r"(?i)D57\.[01248]|282\.4[12]|282\.6"
    "|"
    # Thalassemia (e.g., D56, 282.40)
    r"D56|282\.4[0345679]"
    "|"
    # Trait (e.g., D57.3, 282.5)
    r"D57\.3|282\.5"
    "|"
    # Other/Exclusion (e.g., D58, 282.0)
    r"D58|282\.[0123789]"
)

# Cell 5
# Load Cohort
# We strictly filter all data to the cohort defined in 01-Demographics

if 'e' in locals() and hasattr(e, 'demo'):
    cohort_df = e.demo.df.select('personid', 'tenant').distinct().cache()
    print(f"Processing Cohort Size: {cohort_df.count()}")
else:
    raise ValueError("e.demo.df is not loaded. Please ensure 01-Demographics is run or loaded via LHN Resources.")

# Cell 6
# STEP 1: ENCOUNTER PREPARATION

# Map raw EHR types to Standard Types [Inpatient, Emergency, Outpatient, Admitted for Observation]
type_map_expr = F.create_map([
    F.lit('Inpatient'), F.lit('Inpatient'),
    F.lit('Emergency'), F.lit('Emergency'),
    F.lit('ER'),        F.lit('Emergency'),
    F.lit('Outpatient'), F.lit('Outpatient'),
    F.lit('Admitted for Observation'), F.lit('Admitted for Observation'),
    F.lit('Observation'), F.lit('Admitted for Observation')
])

print("Processing Encounters...")
e.pheno_enc.df = (
    r.encounterSource
    .join(cohort_df, on=['personid', 'tenant'], how='inner')
    .withColumn('mapped_type', type_map_expr.getItem(F.col('encType'))) 
    # Fallback to 'Other' if not in map
    .withColumn('encType', F.coalesce(F.col('mapped_type'), F.lit('Other')))
    .select(
        F.col('personid').alias('id'),
        F.col('tenant'),
        F.col('encounterid'),
        F.col('encType'),
        F.to_date(F.col('servicedate')).alias('encStart'),
        F.to_date(F.col('dischargedate')).alias('encEnd')
    )
    .filter(F.col('encStart').isNotNull())
    .distinct()
)

e.pheno_enc.write.mode("overwrite").parquet(PATH_ENC)
e.pheno_enc.attrition()

# Cell 7
# STEP 2: DIAGNOSIS PREPARATION (Optimized)

print("Processing Diagnoses...")
e.pheno_icd.df = (
    r.conditionFinalSource
    .join(cohort_df, on=['personid', 'tenant'], how='inner')
    # OPTIMIZATION: Superset filter using Regex
    .filter(F.col('conditioncode_standard_id').rlike(ICD_REGEX_SUPERSET))
    .select(
        F.col('personid').alias('id'),
        F.col('tenant'),
        F.col('encounterid'),
        F.col('conditioncode_standard_id').alias('icdCode'),
        F.col('conditioncode_standard_primaryDisplay').alias('icdName'),
        F.to_date(F.col('datetimeCondition')).alias('icdTime')
    )
    .filter(F.col('icdCode').isNotNull())
    .filter(F.col('icdTime').isNotNull())
    .distinct()
)

e.pheno_icd.write.mode("overwrite").parquet(PATH_ICD)
e.pheno_icd.attrition()

# Cell 8
# STEP 3: LAB PREPARATION (Hemoglobin Fractionation)

# Logic: Classify lab rows into Hgb buckets (A, S, F, C, etc.)
lab_case_stmt = (
    F.when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]a$"),           'HgbA')
    .when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]a "),            'HgbA')
    .when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]a2"),            'HgbA2')
    .when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]f"),             'HgbF')
    .when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]s"),             'HgbS')
    .when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]c"),             'HgbC')
    .when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]d"),             'HgbD')
    .when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]e"),             'HgbE')
    .when(F.col('labcode_standard_primaryDisplay').rlike("(?i)Hemoglobin[\s|]o"),             'HgbO')
    .otherwise(None)
)

print("Processing Labs...")
e.pheno_lab.df = (
    r.labSource
    .join(cohort_df, on=['personid', 'tenant'], how='inner')
    # Filter early: Exclude A1c explicitly to reduce noise
    .filter(~F.col('labcode_standard_primaryDisplay').rlike('(?i)a1c')) 
    .withColumn('hgbType', lab_case_stmt)
    .filter(F.col('hgbType').isNotNull()) 
    .select(
        F.col('personid').alias('id'),
        F.col('tenant'),
        F.to_date(F.col('datetimeLab')).alias('time'),
        F.col('hgbType'),
        F.col('typedvalue_numericValue_value').alias('value')
    )
    .filter(F.col('value').isNotNull())
    .distinct()
)

e.pheno_lab.write.mode("overwrite").parquet(PATH_LAB)
e.pheno_lab.attrition()

# Cell 9
# Validation Summary

print("\n--- Pipeline Completion Summary ---")
print(f"1. Encounters: {PATH_ENC}")
print(f"2. Diagnoses:  {PATH_ICD}")
print(f"3. Labs:       {PATH_LAB}")

# Quick peek at the output distributions
print("\n--- ICD Code Distribution (Top 10) ---")
e.pheno_icd.df.groupBy('icdCode').count().orderBy(F.desc('count')).show(10)

print("\n--- Lab Type Distribution ---")
e.pheno_lab.df.groupBy('hgbType').count().orderBy(F.desc('count')).show()