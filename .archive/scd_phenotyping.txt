# Archive created on: 2025-12-12 17:13:00

# Standard Archive Format

# TABLE OF CONTENTS
1. scd_phenotyping/__init__.py
2. scd_phenotyping/config.py
3. scd_phenotyping/icd.py
4. scd_phenotyping/lab.py
5. scd_phenotyping/utils.py

---
Filename: scd_phenotyping/__init__.py
---
from .icd import run_icd_phenotyping
from .lab import classify_lab_row, aggregate_lab_phenotypes
from .utils import clean_enc

__all__ = [
    'run_icd_phenotyping',
    'classify_lab_row',
    'aggregate_lab_phenotypes',
    'clean_enc'
]

---
Filename: scd_phenotyping/config.py
---
# Regex Patterns for ICD Identification
ICD_REGEX = {
    'SCD':   r'D57\.[0,1,2,4,8]|282\.4[1,2]|282\.6',
    'THAL':  r'D56|282\.4[0,3,4,5,6,7,9]',
    'TRAIT': r'D57\.3|282\.5',
    'OTHER': r'D58|282\.[0,1,2,3,7,8,9]'
}

# Standard Encounter Types (Mapped to internal logic)
ENC_TYPES_MAP = {
    'IP': 'Inpatient',
    'ER': 'Emergency',
    'OB': 'Admitted for Observation',
    'OP': 'Outpatient'
}

---
Filename: scd_phenotyping/icd.py
---
import duckdb
import pandas as pd
from . import config as cfg
from . import utils

def run_icd_phenotyping(enc_df, icd_df, col_map):
    """
    Main entry point for ICD-based phenotyping.
    
    Args:
        enc_df (pd.DataFrame): Encounter Data
        icd_df (pd.DataFrame): ICD Data
        col_map (dict): Mapping of column names 
                        Keys: id, encType, encStart, encEnd, icdCode, icdTime
    """
    con = utils.get_con()
    
    # Unpack column names for cleaner SQL
    id_c = col_map['id']
    time_c = col_map['icdTime']
    code_c = col_map['icdCode']
    
    # 1. Categorize ICD Codes
    con.register('icd_df', icd_df)
    
    # Dynamically build Case statement from config regex
    case_stmt = []
    for category, regex in cfg.ICD_REGEX.items():
        case_stmt.append(f"WHEN regexp_matches({code_c}, '{regex}') THEN '{category}'")
    
    sql_cat = f"""
        SELECT DISTINCT
            {id_c}, {time_c},
            CASE {' '.join(case_stmt)} END AS IcdCategory
        FROM icd_df
    """
    icd_cat = con.execute(sql_cat).df()
    
    # 2. Clean Encounters
    # (Assuming enc_df is already reasonably clean, or call utils.clean_enc here)
    # For this package, we assume enc_df passed in is the "cleaned" version
    # or we process it:
    clean_enc_df = utils.clean_enc(
        enc_df, 
        col_map['id'], col_map['encType'], col_map['encStart'], col_map['encEnd'],
        cfg.ENC_TYPES_MAP
    )
    
    con.register('enc', clean_enc_df)
    con.register('icd', icd_cat)
    
    # 3. Join and Summarize
    # This logic replicates the counting of SCD codes vs Thal codes
    # and encounter types (IP vs OP/ER)
    
    sql_summary = f"""
        SELECT 
            e.{id_c},
            -- Count Encounters with specific diagnoses
            SUM(CASE WHEN i.IcdCategory = 'SCD' THEN 1 ELSE 0 END) as count_SCD,
            SUM(CASE WHEN i.IcdCategory = 'THAL' THEN 1 ELSE 0 END) as count_THAL,
            -- Count Encounter Types
            SUM(CASE WHEN e.{col_map['encType']} = '{cfg.ENC_TYPES_MAP['IP']}' THEN 1 ELSE 0 END) as count_IP,
            SUM(CASE WHEN e.{col_map['encType']} IN ('{cfg.ENC_TYPES_MAP['OP']}', '{cfg.ENC_TYPES_MAP['ER']}') THEN 1 ELSE 0 END) as count_OPER
        FROM enc e
        JOIN icd i ON e.{id_c} = i.{id_c}
            AND (i.{time_c} BETWEEN e.{col_map['encStart']} AND e.{col_map['encEnd']} 
                 OR i.{time_c} = e.{col_map['encStart']})
        GROUP BY e.{id_c}
    """
    summary_df = con.execute(sql_summary).df()
    
    # 4. Apply Phenotype Rules (Pandas is often easier for this final step)
    def apply_rule(row):
        # Example rule from original notebook:
        # If > 3 encounters with SCD codes OR (>0 IP encounters with SCD codes)
        # Note: This is a placeholder for the EXACT logic you want to enforce
        if row['count_SCD'] >= 3 or (row['count_IP'] >= 1 and row['count_SCD'] >= 1):
            return 'SCD_Case'
        elif row['count_THAL'] > row['count_SCD']:
            return 'Thalassemia'
        else:
            return 'Possible/Control'

    summary_df['IcdPheno'] = summary_df.apply(apply_rule, axis=1)
    
    return summary_df

---
Filename: scd_phenotyping/lab.py
---
import pandas as pd
import numpy as np

def calculate_ratios(df):
    """
    Calculates HbS %, HbA %, etc. assuming standard column names.
    Expects wide format: HgbA, HgbS, HgbF, HgbC columns.
    """
    df['total_hgb'] = df[['HgbA', 'HgbS', 'HgbF', 'HgbC']].sum(axis=1)
    
    # Avoid division by zero
    mask = df['total_hgb'] > 0
    df.loc[mask, 'S_percent'] = (df.loc[mask, 'HgbS'] / df.loc[mask, 'total_hgb']) * 100
    df.loc[mask, 'A_percent'] = (df.loc[mask, 'HgbA'] / df.loc[mask, 'total_hgb']) * 100
    
    return df

def classify_lab_row(row):
    """
    Classifies a SINGLE lab result row based on Hgb fractions.
    """
    s = row.get('S_percent', 0)
    a = row.get('A_percent', 0)
    
    if s > 50 and a < 10:
        return 'SCD_SS' # Likely SS or S-beta0
    elif s > 0 and a > s:
        return 'S_Trait'
    # ... Add specific SC, S-beta+ logic here based on your clinical rules
    else:
        return 'Inconclusive'

def aggregate_lab_phenotypes(lab_df, id_col='personid', pheno_col='LabPhenotype'):
    """
    Aggregates row-level phenotypes to patient level (Mode/Majority Vote).
    """
    # Simply take the most frequent phenotype per person
    return (
        lab_df
        .groupby(id_col)[pheno_col]
        .agg(lambda x: x.mode().iloc[0] if not x.mode().empty else 'Unknown')
        .reset_index()
    )

---
Filename: scd_phenotyping/utils.py
---
import duckdb
import pandas as pd

def get_con():
    """Returns a fresh in-memory DuckDB connection."""
    return duckdb.connect()

def clean_enc(encDF, id_col, type_col, start_col, end_col, types_map):
    """
    Cleans encounter data:
    1. Removes duplicates
    2. Merges overlapping IP/ER/OB encounters
    3. Handles long stays (>365 days)
    """
    con = get_con()
    
    # 1. Register Data
    con.register('encDF', encDF)
    
    # 2. Basic Dedup
    sql_dedup = f"SELECT DISTINCT {id_col}, {type_col}, {start_col}, {end_col} FROM encDF"
    cleaned = con.execute(sql_dedup).df()
    
    # 3. Identify Multi-Day types
    multi_types = [types_map['IP'], types_map['ER'], types_map['OB']]
    multi_types_str = "', '".join(multi_types)
    
    con.register('cleaned', cleaned)
    
    # Logic: Filter valid multi-day encounters < 365 days
    sql_multi = f"""
        SELECT *,
            (CAST({end_col} AS DECIMAL) - CAST({start_col} AS DECIMAL)) as days
        FROM cleaned
        WHERE {type_col} IN ('{multi_types_str}')
          AND {end_col} IS NOT NULL
    """
    multi_day = con.execute(sql_multi).df()
    valid_multi = multi_day[multi_day['days'] < 365].drop(columns=['days'])
    
    # 4. Handle Outpatient (Single Day)
    op_type = types_map['OP']
    con.register('valid_multi', valid_multi)
    
    sql_op = f"""
        SELECT DISTINCT c.*
        FROM cleaned c
        WHERE c.{type_col} = '{op_type}'
    """
    op_enc = con.execute(sql_op).df()
    # Ensure OP has null end date (standard logic)
    op_enc[end_col] = None
    
    con.register('op_enc', op_enc)
    
    # 5. Remove OP encounters that occur DURING a valid IP/ER stay
    sql_final = f"""
        SELECT m.* FROM valid_multi m
        UNION
        SELECT o.* FROM op_enc o
        LEFT JOIN valid_multi m ON m.{id_col} = o.{id_col}
            AND o.{start_col} BETWEEN m.{start_col} AND m.{end_col}
        WHERE m.{id_col} IS NULL
    """
    final_df = con.execute(sql_final).df()
    con.close()
    
    return final_df.sort_values([id_col, start_col])

